{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CE888-Assignment-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Registration Number : 2007253\n",
        "### Project : seq2seq : Natural Language to SQL Query Conversion\n"
      ],
      "metadata": {
        "id": "LxeMTpViKIvp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### References: For the code and architecture used in this notebook references are taken from the book: Deep Learning with Python (Second Edition) by Francois Chollet.\n",
        "\n",
        "##### In the chapter-11, Deep Learning for Text, the authour has proposed a GRU based sequence-to-sequence Neural Network on English to Spanish Translation. Using this work as a baseline, I have tried to replicate the Neural Network on the Yale Spider dataset.\n",
        "\n",
        "#####  Also, I have extented the original experiment to use Bi-Directional LSTMs (single and multi-layer) and computed BLEU score for different simulations done on the Yale Spider Dataset."
      ],
      "metadata": {
        "id": "HhhHvtY0KEc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Below are the results inferred from different sequence-to-sequence models simulated\n",
        "\n",
        "#### Model-1 : Single Layer BiLSTM-GRU\n",
        "1. Test Set BLEU Score : 0.145068\n",
        "2. Validation Set BLEU Score : 0.141787\n",
        "\n",
        "#### Model-2 : Single Layer BiLSTM\n",
        "1. Test Set BLEU Score : 0.154295\n",
        "2. Validation Set BLEU Score : 0.150324\n",
        "\n",
        "#### Model-3 : Two Layer BiLSTM\n",
        "1. Test Set BLEU Score : 0.165978\n",
        "2. Validation Set BLEU Score : 0.161283\n",
        "\n",
        "#### Model-4 : Three Layer BiLSTM\n",
        "1. Test Set BLEU Score : 0.153336\n",
        "2. Validation Set BLEU Score : 1.000"
      ],
      "metadata": {
        "id": "fGC3xL-gnaBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Packages"
      ],
      "metadata": {
        "id": "m813XLPFMZIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "wa2cE_jULqN3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve Datasets"
      ],
      "metadata": {
        "id": "YVbsL1IaMeWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## These paths are from my Google drive\n",
        "\n",
        "train_path = '/content/drive/MyDrive/CE888/Spider/train_others.json'\n",
        "train_other_path = '/content/drive/MyDrive/CE888/Spider/train_spider.json'\n",
        "\n",
        "train_data = pd.read_json(train_path)\n",
        "train_other_data = pd.read_json(train_other_path)"
      ],
      "metadata": {
        "id": "8T40KqVlMbpl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Concatenate Datasets"
      ],
      "metadata": {
        "id": "m6XnUheWM2oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.concat([train_data, train_other_data], axis=0, ignore_index=True)\n",
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "2axDnMn0Mx_H",
        "outputId": "238291b5-4e4c-4018-a9b8-907f519047c1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  db_id                                              query  \\\n",
              "0   geo  SELECT city_name FROM city WHERE population  =...   \n",
              "1   geo  SELECT city_name FROM city WHERE population  =...   \n",
              "2   geo  SELECT city_name FROM city WHERE population  =...   \n",
              "3   geo  SELECT city_name FROM city WHERE population  =...   \n",
              "4   geo  SELECT city_name FROM city WHERE population  =...   \n",
              "\n",
              "                                          query_toks  \\\n",
              "0  [SELECT, city_name, FROM, city, WHERE, populat...   \n",
              "1  [SELECT, city_name, FROM, city, WHERE, populat...   \n",
              "2  [SELECT, city_name, FROM, city, WHERE, populat...   \n",
              "3  [SELECT, city_name, FROM, city, WHERE, populat...   \n",
              "4  [SELECT, city_name, FROM, city, WHERE, populat...   \n",
              "\n",
              "                                 query_toks_no_value  \\\n",
              "0  [select, city_name, from, city, where, populat...   \n",
              "1  [select, city_name, from, city, where, populat...   \n",
              "2  [select, city_name, from, city, where, populat...   \n",
              "3  [select, city_name, from, city, where, populat...   \n",
              "4  [select, city_name, from, city, where, populat...   \n",
              "\n",
              "                                           question  \\\n",
              "0               what is the biggest city in wyoming   \n",
              "1      what wyoming city has the largest population   \n",
              "2               what is the largest city in wyoming   \n",
              "3       where is the most populated area of wyoming   \n",
              "4  which city in wyoming has the largest population   \n",
              "\n",
              "                                       question_toks  \\\n",
              "0        [what, is, the, biggest, city, in, wyoming]   \n",
              "1  [what, wyoming, city, has, the, largest, popul...   \n",
              "2        [what, is, the, largest, city, in, wyoming]   \n",
              "3  [where, is, the, most, populated, area, of, wy...   \n",
              "4  [which, city, in, wyoming, has, the, largest, ...   \n",
              "\n",
              "                                                 sql  \n",
              "0  {'from': {'table_units': [['table_unit', 1]], ...  \n",
              "1  {'from': {'table_units': [['table_unit', 1]], ...  \n",
              "2  {'from': {'table_units': [['table_unit', 1]], ...  \n",
              "3  {'from': {'table_units': [['table_unit', 1]], ...  \n",
              "4  {'from': {'table_units': [['table_unit', 1]], ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbb5f3ca-c130-4ee3-98a1-ebea3b14b3c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>db_id</th>\n",
              "      <th>query</th>\n",
              "      <th>query_toks</th>\n",
              "      <th>query_toks_no_value</th>\n",
              "      <th>question</th>\n",
              "      <th>question_toks</th>\n",
              "      <th>sql</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>geo</td>\n",
              "      <td>SELECT city_name FROM city WHERE population  =...</td>\n",
              "      <td>[SELECT, city_name, FROM, city, WHERE, populat...</td>\n",
              "      <td>[select, city_name, from, city, where, populat...</td>\n",
              "      <td>what is the biggest city in wyoming</td>\n",
              "      <td>[what, is, the, biggest, city, in, wyoming]</td>\n",
              "      <td>{'from': {'table_units': [['table_unit', 1]], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>geo</td>\n",
              "      <td>SELECT city_name FROM city WHERE population  =...</td>\n",
              "      <td>[SELECT, city_name, FROM, city, WHERE, populat...</td>\n",
              "      <td>[select, city_name, from, city, where, populat...</td>\n",
              "      <td>what wyoming city has the largest population</td>\n",
              "      <td>[what, wyoming, city, has, the, largest, popul...</td>\n",
              "      <td>{'from': {'table_units': [['table_unit', 1]], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>geo</td>\n",
              "      <td>SELECT city_name FROM city WHERE population  =...</td>\n",
              "      <td>[SELECT, city_name, FROM, city, WHERE, populat...</td>\n",
              "      <td>[select, city_name, from, city, where, populat...</td>\n",
              "      <td>what is the largest city in wyoming</td>\n",
              "      <td>[what, is, the, largest, city, in, wyoming]</td>\n",
              "      <td>{'from': {'table_units': [['table_unit', 1]], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>geo</td>\n",
              "      <td>SELECT city_name FROM city WHERE population  =...</td>\n",
              "      <td>[SELECT, city_name, FROM, city, WHERE, populat...</td>\n",
              "      <td>[select, city_name, from, city, where, populat...</td>\n",
              "      <td>where is the most populated area of wyoming</td>\n",
              "      <td>[where, is, the, most, populated, area, of, wy...</td>\n",
              "      <td>{'from': {'table_units': [['table_unit', 1]], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>geo</td>\n",
              "      <td>SELECT city_name FROM city WHERE population  =...</td>\n",
              "      <td>[SELECT, city_name, FROM, city, WHERE, populat...</td>\n",
              "      <td>[select, city_name, from, city, where, populat...</td>\n",
              "      <td>which city in wyoming has the largest population</td>\n",
              "      <td>[which, city, in, wyoming, has, the, largest, ...</td>\n",
              "      <td>{'from': {'table_units': [['table_unit', 1]], ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbb5f3ca-c130-4ee3-98a1-ebea3b14b3c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fbb5f3ca-c130-4ee3-98a1-ebea3b14b3c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fbb5f3ca-c130-4ee3-98a1-ebea3b14b3c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a List of 'Question' and 'Query' values from the dataset"
      ],
      "metadata": {
        "id": "ksJ6t7QEM8co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_pairs = []\n",
        "for i in range (len(train_data)):\n",
        "    question=train_data.loc[i, \"question\"]\n",
        "    query=train_data.loc[i, \"query\"]\n",
        "    query = \"[start] \" + query + \" [end]\"\n",
        "    text_pairs.append((question, query))"
      ],
      "metadata": {
        "id": "9WMfyxbnM5gh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Training, Testing & Validation Sets"
      ],
      "metadata": {
        "id": "ypJl0TT7NGD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]"
      ],
      "metadata": {
        "id": "a8LLo6inNDYh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Total Training Pairs:', len(train_pairs))\n",
        "print ('Total Testing Pairs:', len(test_pairs))\n",
        "print ('Total Validation Pairs:', len(val_pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S5fWrreNKxD",
        "outputId": "f4167511-6948-4bd4-ef94-f748a4a3e55a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Training Pairs: 6063\n",
            "Total Testing Pairs: 1298\n",
            "Total Validation Pairs: 1298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform Data Preprocessing which involves casefolding and Text Vectorizsation"
      ],
      "metadata": {
        "id": "rZM0hndSN7XC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 15000\n",
        "sequence_length = 64\n",
        "batch_size = 128\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return lowercase\n",
        "\n",
        "question_vectorization = TextVectorization(max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,)\n",
        "query_vectorization = TextVectorization(max_tokens=vocab_size,  output_mode=\"int\", output_sequence_length=sequence_length + 1, standardize=custom_standardization)\n"
      ],
      "metadata": {
        "id": "XA0WdE43NRD0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_question_texts = [pair[0] for pair in train_pairs]\n",
        "train_query_texts = [pair[1] for pair in train_pairs]\n",
        "question_vectorization.adapt(train_question_texts)\n",
        "query_vectorization.adapt(train_query_texts)"
      ],
      "metadata": {
        "id": "fJygEiruOKSL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(question, query):\n",
        "    question = question_vectorization(question)\n",
        "    query = query_vectorization(query)\n",
        "    return ({\"encoder_inputs\": question, \"decoder_inputs\": query[:, :-1],}, query[:, 1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    question_texts, query_texts = zip(*pairs)\n",
        "    question_texts = list(question_texts)\n",
        "    query_texts = list(query_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((question_texts, query_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()"
      ],
      "metadata": {
        "id": "twTyUYy3ON7g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = make_dataset(train_pairs)\n",
        "test_ds = make_dataset(test_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "metadata": {
        "id": "xnF2rhGvOQvI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRHSYkx6OdRL",
        "outputId": "0963835f-4221-4319-c28b-7e222f1f8ab9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (128, 64)\n",
            "inputs[\"decoder_inputs\"].shape: (128, 64)\n",
            "targets.shape: (128, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Parameters for the Embeddings"
      ],
      "metadata": {
        "id": "znBEYM5GOtG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 1024"
      ],
      "metadata": {
        "id": "R0NphX3IOi9_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: Single Layer Bidirectional GRU"
      ],
      "metadata": {
        "id": "L7g4HMFnOys7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
        "encoded_source = layers.Bidirectional(layers.GRU(latent_dim), merge_mode=\"sum\")(x)"
      ],
      "metadata": {
        "id": "8uIX55SsOo4X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
        "decoder_gru = layers.GRU(latent_dim, return_sequences=True)\n",
        "x = decoder_gru(x, initial_state=encoded_source)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)"
      ],
      "metadata": {
        "id": "eY4pvWzpO6R1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq_01 = keras.Model([source, past_target], target_next_step)"
      ],
      "metadata": {
        "id": "vZWOqPTiPama"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Callbacks"
      ],
      "metadata": {
        "id": "s4EYCLDRPl8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [EarlyStopping(monitor='val_accuracy', patience=1),\n",
        "             ModelCheckpoint(\"seq2seq_01.keras\", save_best_only=True, monitor=\"val_accuracy\", mode='max')]\n"
      ],
      "metadata": {
        "id": "Zr-ff8pSPMy1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile and Run the model"
      ],
      "metadata": {
        "id": "LRj9pfoZPp2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq_01.compile(\n",
        "optimizer=\"rmsprop\",\n",
        "loss=\"sparse_categorical_crossentropy\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "seq2seq_01.fit(train_ds, epochs=30, validation_data=val_ds, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc5R15SUPHLd",
        "outputId": "e4acf342-5cce-4704-85db-00f7960c562f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "48/48 [==============================] - 50s 691ms/step - loss: 1.8761 - accuracy: 0.2072 - val_loss: 1.3069 - val_accuracy: 0.3332\n",
            "Epoch 2/30\n",
            "48/48 [==============================] - 29s 602ms/step - loss: 1.1756 - accuracy: 0.4076 - val_loss: 1.1764 - val_accuracy: 0.4827\n",
            "Epoch 3/30\n",
            "48/48 [==============================] - 29s 606ms/step - loss: 0.9811 - accuracy: 0.4829 - val_loss: 1.1687 - val_accuracy: 0.4900\n",
            "Epoch 4/30\n",
            "48/48 [==============================] - 29s 608ms/step - loss: 0.8833 - accuracy: 0.5138 - val_loss: 1.1298 - val_accuracy: 0.5139\n",
            "Epoch 5/30\n",
            "48/48 [==============================] - 29s 608ms/step - loss: 0.8113 - accuracy: 0.5419 - val_loss: 1.1326 - val_accuracy: 0.5231\n",
            "Epoch 6/30\n",
            "48/48 [==============================] - 29s 595ms/step - loss: 0.7625 - accuracy: 0.5627 - val_loss: 1.1457 - val_accuracy: 0.5184\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f113ef1d550>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference/Decode the Input for making predictions"
      ],
      "metadata": {
        "id": "9UDX1OMJP18U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_vocab = query_vectorization.get_vocabulary()\n",
        "query_index_lookup = dict(zip(range(len(query_vocab)), query_vocab))\n",
        "max_decoded_sentence_length = 20"
      ],
      "metadata": {
        "id": "lVUYrXuTP0GC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence_01(input_sentence):\n",
        "  tokenized_input_sentence = question_vectorization([input_sentence])\n",
        "  decoded_sentence = \"[start]\"\n",
        "  for i in range(max_decoded_sentence_length):\n",
        "    tokenized_target_sentence = query_vectorization([decoded_sentence])\n",
        "    next_token_predictions = seq2seq_01.predict([tokenized_input_sentence, tokenized_target_sentence])\n",
        "    sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
        "\n",
        "    sampled_token = query_index_lookup[sampled_token_index]\n",
        "    decoded_sentence += \" \" + sampled_token\n",
        "    if sampled_token == \"[end]\":\n",
        "      break\n",
        "  return decoded_sentence"
      ],
      "metadata": {
        "id": "bD660Dq7QEFE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute BLEU Score on Test Dataset"
      ],
      "metadata": {
        "id": "ge2Yis_GQHIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in test_pairs]\n",
        "query_texts = [pair[1] for pair in test_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_01(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Test Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUeiDd6XQMw0",
        "outputId": "204ffe83-cfaf-4994-ba0f-be516bc06894"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-1 Score on Test Dataset: 0.145068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some Predictions simulated on Test set"
      ],
      "metadata": {
        "id": "zJAisrBpRivt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_questions_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(5):\n",
        "  input_sentence = random.choice(test_questions_texts)\n",
        "  print(\"-\")\n",
        "  print(input_sentence)\n",
        "  print(decode_sequence_01(input_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmiz0G5eRhSM",
        "outputId": "64a4d300-494c-473e-c375-f70614930400"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Find the name, type, and flag of the ship that is built in the most recent year.\n",
            "[start] select t1.name from category as t2 join business as t1 on t2.business_id = t1.business_id join student as t3 on t3.business_id\n",
            "-\n",
            "Find the phone number of all the customers and staff.\n",
            "[start] select t1.name from category as t2 join business as t1 on t2.business_id = t1.business_id join student as t3 on t3.business_id\n",
            "-\n",
            "Which three cities have the largest regional population?\n",
            "[start] select state_name from state where area = ( select max ( area ) from state ); [end]\n",
            "-\n",
            "Who made the latest order?\n",
            "[start] select t1.name from category as t2 join business as t1 on t2.business_id = t1.business_id join student as t3 on t3.business_id\n",
            "-\n",
            "List the cities which have more than 2 airports sorted by the number of airports.\n",
            "[start] select t1.name from category as t2 join business as t1 on t2.business_id = t1.business_id join student as t3 on t3.business_id\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute BLEU Score on Validation Dataset"
      ],
      "metadata": {
        "id": "fz09Rf9cQgo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in val_pairs]\n",
        "query_texts = [pair[1] for pair in val_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_01(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Validation Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPgp9L3gQgQ0",
        "outputId": "e440147b-0be8-48ca-8e3b-b8c53ae51573"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-1 Score on Validation Dataset: 0.141787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: Single Layer Bidirectional LSTM"
      ],
      "metadata": {
        "id": "W4BvLspLQ_Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
        "out_encoder, state_h_forward, state_c_forward, state_h_backward, state_c_backward = layers.Bidirectional(layers.LSTM(latent_dim, return_sequences=True, return_state=True), merge_mode=\"sum\")(x)\n"
      ],
      "metadata": {
        "id": "wVgB0VLfR0NJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
        "decoder_LSTM = layers.LSTM(latent_dim, return_sequences=True)\n",
        "\n",
        "encoder_state=[state_h_forward, state_c_forward]\n",
        "\n",
        "x = decoder_LSTM(x, initial_state=encoder_state)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)"
      ],
      "metadata": {
        "id": "mQskkQklSCX-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq_02 = keras.Model([source, past_target], target_next_step)"
      ],
      "metadata": {
        "id": "A6Du9NpOSCQU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [EarlyStopping(monitor='val_accuracy', patience=1),\n",
        "             ModelCheckpoint(\"seq2seq_02.keras\", save_best_only=True, monitor=\"val_accuracy\", mode='max')]\n"
      ],
      "metadata": {
        "id": "v09ub95qSbzL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq_02.compile(\n",
        "optimizer=\"rmsprop\",\n",
        "loss=\"sparse_categorical_crossentropy\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "seq2seq_02.fit(train_ds, epochs=30, validation_data=val_ds, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUAv3BFfSffW",
        "outputId": "f7815a39-e47f-4ed3-c491-2f18a3158ff4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['bidirectional_8/backward_lstm_10/lstm_cell_26/kernel:0', 'bidirectional_8/backward_lstm_10/lstm_cell_26/recurrent_kernel:0', 'bidirectional_8/backward_lstm_10/lstm_cell_26/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['bidirectional_8/backward_lstm_10/lstm_cell_26/kernel:0', 'bidirectional_8/backward_lstm_10/lstm_cell_26/recurrent_kernel:0', 'bidirectional_8/backward_lstm_10/lstm_cell_26/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "48/48 [==============================] - 47s 685ms/step - loss: 1.8294 - accuracy: 0.1676 - val_loss: 1.3529 - val_accuracy: 0.2946\n",
            "Epoch 2/30\n",
            "48/48 [==============================] - 28s 593ms/step - loss: 1.3327 - accuracy: 0.2941 - val_loss: 1.2316 - val_accuracy: 0.3653\n",
            "Epoch 3/30\n",
            "48/48 [==============================] - 29s 593ms/step - loss: 1.1250 - accuracy: 0.3929 - val_loss: 1.1527 - val_accuracy: 0.4649\n",
            "Epoch 4/30\n",
            "48/48 [==============================] - 28s 593ms/step - loss: 0.9815 - accuracy: 0.4652 - val_loss: 1.1257 - val_accuracy: 0.5016\n",
            "Epoch 5/30\n",
            "48/48 [==============================] - 29s 593ms/step - loss: 0.8887 - accuracy: 0.5032 - val_loss: 1.1122 - val_accuracy: 0.5114\n",
            "Epoch 6/30\n",
            "48/48 [==============================] - 28s 581ms/step - loss: 0.8250 - accuracy: 0.5271 - val_loss: 1.1180 - val_accuracy: 0.5080\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f10955b0990>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_vocab = query_vectorization.get_vocabulary()\n",
        "query_index_lookup = dict(zip(range(len(query_vocab)), query_vocab))\n",
        "max_decoded_sentence_length = 20"
      ],
      "metadata": {
        "id": "FE9dk83zSoQa"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence_02(input_sentence):\n",
        "  tokenized_input_sentence = question_vectorization([input_sentence])\n",
        "  decoded_sentence = \"[start]\"\n",
        "  for i in range(max_decoded_sentence_length):\n",
        "    tokenized_target_sentence = query_vectorization([decoded_sentence])\n",
        "    next_token_predictions = seq2seq_02.predict([tokenized_input_sentence, tokenized_target_sentence])\n",
        "    sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
        "\n",
        "    sampled_token = query_index_lookup[sampled_token_index]\n",
        "    decoded_sentence += \" \" + sampled_token\n",
        "    if sampled_token == \"[end]\":\n",
        "      break\n",
        "  return decoded_sentence"
      ],
      "metadata": {
        "id": "WI8G6323SsvE"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in test_pairs]\n",
        "query_texts = [pair[1] for pair in test_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_02(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Test Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K59XzW5RS11P",
        "outputId": "8a001a85-3a11-46ac-cc52-4626a8ea867b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-1 Score on Test Dataset: 0.154295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_questions_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(5):\n",
        "  input_sentence = random.choice(test_questions_texts)\n",
        "  print(\"-\")\n",
        "  print(input_sentence)\n",
        "  print(decode_sequence_02(input_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMPiSV17S9lB",
        "outputId": "0a296105-e6c3-4a5a-f773-3f749f3a7ccf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "How many airports haven't the pilot 'Thompson' driven an aircraft?\n",
            "[start] select distinct ( ( ) from paperkeyphrase as t2 join keyphrase as t1 on t2.authorid = t1.authorid where t1.authorname =\n",
            "-\n",
            "Show the average price of hotels for different pet policy.\n",
            "[start] select t1.name from publication as t1 join author as t2 on t1.id = t2.customer_id where t1.name = \"san and t3.name\n",
            "-\n",
            "Return complaint status codes have more than 3 corresponding complaints?\n",
            "[start] select distinct ( ( ) from writes as t2 join author as t1 on t2.authorid = t1.authorid where t1.authorname =\n",
            "-\n",
            "Return the description of the product called \"Chocolate\".\n",
            "[start] select distinct ( ( ) from paperkeyphrase as t2 join keyphrase as t1 on t2.authorid = t1.authorid where t1.authorname =\n",
            "-\n",
            "What are the country names, area and population which has both roller coasters with speed higher\n",
            "[start] select t1.name from publication as t1 join author as t2 on t1.id = t2.customer_id where t1.name = \"san and t3.name\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in val_pairs]\n",
        "query_texts = [pair[1] for pair in val_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_02(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Validation Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2cZZcazS9hQ",
        "outputId": "ea81b48b-bc75-484f-8aed-e9d4e3093e5b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-1 Score on Validation Dataset: 0.150324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: Two Layer Bidirectional LSTM"
      ],
      "metadata": {
        "id": "35ypO_WURGnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
        "encoded_source = layers.Bidirectional(layers.LSTM(latent_dim), merge_mode=\"sum\")(x)\n",
        "out_encoder1, state_h_forward1, state_c_forward1, state_h_backward1, state_c_backward1 = layers.Bidirectional(layers.LSTM(latent_dim, return_sequences=True, return_state=True), merge_mode=\"sum\")(x)\n",
        "out_encoder2, state_h_forward2, state_c_forward2, state_h_backward2, state_c_backward2 = layers.Bidirectional(layers.LSTM(latent_dim, return_sequences=True, return_state=True), merge_mode=\"sum\")(out_encoder1)\n"
      ],
      "metadata": {
        "id": "9LDLXF0RTRkh"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
        "decoder_LSTM = layers.LSTM(latent_dim, return_sequences=True)\n",
        "\n",
        "encoder_state=[state_h_forward2, state_c_forward2]\n",
        "\n",
        "x = decoder_LSTM(x, initial_state=encoder_state)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)"
      ],
      "metadata": {
        "id": "Njn--9p0TRkh"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq_03 = keras.Model([source, past_target], target_next_step)"
      ],
      "metadata": {
        "id": "YTqM0ynqTRkh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [EarlyStopping(monitor='val_accuracy', patience=1),\n",
        "             ModelCheckpoint(\"seq2seq_03.keras\", save_best_only=True, monitor=\"val_accuracy\", mode='max')]\n"
      ],
      "metadata": {
        "id": "642UwHOqTRkh"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq_03.compile(\n",
        "optimizer=\"rmsprop\",\n",
        "loss=\"sparse_categorical_crossentropy\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "seq2seq_03.fit(train_ds, epochs=30, validation_data=val_ds, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMD9Jke4TRki",
        "outputId": "3166e327-91b2-456f-89a0-36341e067e18"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['bidirectional_11/backward_lstm_15/lstm_cell_37/kernel:0', 'bidirectional_11/backward_lstm_15/lstm_cell_37/recurrent_kernel:0', 'bidirectional_11/backward_lstm_15/lstm_cell_37/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['bidirectional_11/backward_lstm_15/lstm_cell_37/kernel:0', 'bidirectional_11/backward_lstm_15/lstm_cell_37/recurrent_kernel:0', 'bidirectional_11/backward_lstm_15/lstm_cell_37/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "48/48 [==============================] - 67s 903ms/step - loss: 1.8313 - accuracy: 0.1673 - val_loss: 1.3530 - val_accuracy: 0.2966\n",
            "Epoch 2/30\n",
            "48/48 [==============================] - 36s 744ms/step - loss: 1.3280 - accuracy: 0.2958 - val_loss: 1.2243 - val_accuracy: 0.3682\n",
            "Epoch 3/30\n",
            "48/48 [==============================] - 36s 757ms/step - loss: 1.1154 - accuracy: 0.4000 - val_loss: 1.1466 - val_accuracy: 0.4745\n",
            "Epoch 4/30\n",
            "48/48 [==============================] - 36s 752ms/step - loss: 0.9577 - accuracy: 0.4800 - val_loss: 1.1091 - val_accuracy: 0.5102\n",
            "Epoch 5/30\n",
            "48/48 [==============================] - 36s 750ms/step - loss: 0.8669 - accuracy: 0.5167 - val_loss: 1.0914 - val_accuracy: 0.5123\n",
            "Epoch 6/30\n",
            "48/48 [==============================] - 35s 726ms/step - loss: 0.7983 - accuracy: 0.5416 - val_loss: 1.1284 - val_accuracy: 0.4966\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1091406fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_vocab = query_vectorization.get_vocabulary()\n",
        "query_index_lookup = dict(zip(range(len(query_vocab)), query_vocab))\n",
        "max_decoded_sentence_length = 20"
      ],
      "metadata": {
        "id": "3ggEiKUhTRki"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence_03(input_sentence):\n",
        "  tokenized_input_sentence = question_vectorization([input_sentence])\n",
        "  decoded_sentence = \"[start]\"\n",
        "  for i in range(max_decoded_sentence_length):\n",
        "    tokenized_target_sentence = query_vectorization([decoded_sentence])\n",
        "    next_token_predictions = seq2seq_03.predict([tokenized_input_sentence, tokenized_target_sentence])\n",
        "    sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
        "\n",
        "    sampled_token = query_index_lookup[sampled_token_index]\n",
        "    decoded_sentence += \" \" + sampled_token\n",
        "    if sampled_token == \"[end]\":\n",
        "      break\n",
        "  return decoded_sentence"
      ],
      "metadata": {
        "id": "_EOantacTRki"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in test_pairs]\n",
        "query_texts = [pair[1] for pair in test_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_03(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Test Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEjCoPTcTRki",
        "outputId": "7b45e282-aa67-4403-dd71-89ce295fc58b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-1 Score on Test Dataset: 0.165978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_questions_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(5):\n",
        "  input_sentence = random.choice(test_questions_texts)\n",
        "  print(\"-\")\n",
        "  print(input_sentence)\n",
        "  print(decode_sequence_03(input_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc9TMD4ETRki",
        "outputId": "ff636e0b-4b03-4e5f-f2b1-b9c1fe1259b7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "When did Carole Bernhard first become a customer?\n",
            "[start] select distinct ( ( ) ) from paperkeyphrase as t2 join author as t1 on t2.authorid = t1.authorid join writes\n",
            "-\n",
            "Find the number of investors in total.\n",
            "[start] select distinct ( ( ) ) from paperkeyphrase as t2 join author as t1 on t2.authorid = t1.authorid join writes\n",
            "-\n",
            "What are the names and descriptions of the photos taken at the tourist attraction \"film festival\"?\n",
            "[start] select count(*) from state where name = (select select = ( and state = ( select max ( ( )\n",
            "-\n",
            "List ids and details for all projects.\n",
            "[start] select distinct ( ( ) ) from paperkeyphrase as t2 join author as t1 on t2.authorid = t1.authorid join writes\n",
            "-\n",
            "How many activities does Mark Giuliano participate in?\n",
            "[start] select distinct ( ( ) ) from paperkeyphrase as t2 join author as t1 on t2.authorid = t1.authorid join writes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in val_pairs]\n",
        "query_texts = [pair[1] for pair in val_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_03(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Validation Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0pNM612TRki",
        "outputId": "31e862fc-8e84-455e-c18a-377fed6cf06b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-1 Score on Validation Dataset: 0.161283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4: Three Layer Bidirectional LSTM"
      ],
      "metadata": {
        "id": "yHfbS6PpRKXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
        "encoded_source = layers.Bidirectional(layers.LSTM(latent_dim), merge_mode=\"sum\")(x)\n",
        "out_encoder1, state_h_forward1, state_c_forward1, state_h_backward1, state_c_backward1 = layers.Bidirectional(layers.LSTM(latent_dim, return_sequences=True, return_state=True), merge_mode=\"sum\")(x)\n",
        "out_encoder2, state_h_forward2, state_c_forward2, state_h_backward2, state_c_backward2 = layers.Bidirectional(layers.LSTM(latent_dim, return_sequences=True, return_state=True), merge_mode=\"sum\")(out_encoder1)\n",
        "out_encoder3, state_h_forward3, state_c_forward3, state_h_backward3, state_c_backward3 = layers.Bidirectional(layers.LSTM(latent_dim, return_sequences=True, return_state=True), merge_mode=\"sum\")(out_encoder2)\n"
      ],
      "metadata": {
        "id": "4izdBGYpUU7a"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
        "decoder_LSTM = layers.LSTM(latent_dim, return_sequences=True)\n",
        "\n",
        "encoder_state=[state_h_forward3, state_c_forward3]\n",
        "\n",
        "x = decoder_LSTM(x, initial_state=encoder_state)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)"
      ],
      "metadata": {
        "id": "YMoJZ5TdUU7b"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq_04 = keras.Model([source, past_target], target_next_step)"
      ],
      "metadata": {
        "id": "mrHcq2NiUU7b"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [EarlyStopping(monitor='val_accuracy', patience=1),\n",
        "             ModelCheckpoint(\"seq2seq_04.keras\", save_best_only=True, monitor=\"val_accuracy\", mode='max')]\n"
      ],
      "metadata": {
        "id": "IYviOfjFUU7b"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq_04.compile(\n",
        "optimizer=\"rmsprop\",\n",
        "loss=\"sparse_categorical_crossentropy\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "seq2seq_04.fit(train_ds, epochs=30, validation_data=val_ds, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqIet5FjUU7b",
        "outputId": "97c79441-964e-40d8-96e1-742b5db503b2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['bidirectional_15/backward_lstm_20/lstm_cell_50/kernel:0', 'bidirectional_15/backward_lstm_20/lstm_cell_50/recurrent_kernel:0', 'bidirectional_15/backward_lstm_20/lstm_cell_50/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['bidirectional_15/backward_lstm_20/lstm_cell_50/kernel:0', 'bidirectional_15/backward_lstm_20/lstm_cell_50/recurrent_kernel:0', 'bidirectional_15/backward_lstm_20/lstm_cell_50/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "48/48 [==============================] - 86s 1s/step - loss: 1.8287 - accuracy: 0.1690 - val_loss: 1.3511 - val_accuracy: 0.2822\n",
            "Epoch 2/30\n",
            "48/48 [==============================] - 45s 935ms/step - loss: 1.3266 - accuracy: 0.2963 - val_loss: 1.2336 - val_accuracy: 0.3680\n",
            "Epoch 3/30\n",
            "48/48 [==============================] - 45s 937ms/step - loss: 1.1135 - accuracy: 0.4054 - val_loss: 1.1604 - val_accuracy: 0.4690\n",
            "Epoch 4/30\n",
            "48/48 [==============================] - 44s 926ms/step - loss: 0.9691 - accuracy: 0.4730 - val_loss: 1.1358 - val_accuracy: 0.5002\n",
            "Epoch 5/30\n",
            "48/48 [==============================] - 45s 933ms/step - loss: 0.8807 - accuracy: 0.5067 - val_loss: 1.1112 - val_accuracy: 0.5098\n",
            "Epoch 6/30\n",
            "48/48 [==============================] - 45s 934ms/step - loss: 0.8203 - accuracy: 0.5315 - val_loss: 1.1177 - val_accuracy: 0.5189\n",
            "Epoch 7/30\n",
            "48/48 [==============================] - 43s 898ms/step - loss: 0.7730 - accuracy: 0.5476 - val_loss: 1.1170 - val_accuracy: 0.5140\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f108a9b7650>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_vocab = query_vectorization.get_vocabulary()\n",
        "query_index_lookup = dict(zip(range(len(query_vocab)), query_vocab))\n",
        "max_decoded_sentence_length = 20"
      ],
      "metadata": {
        "id": "-5R-dUg4UU7c"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence_04(input_sentence):\n",
        "  tokenized_input_sentence = question_vectorization([input_sentence])\n",
        "  decoded_sentence = \"[start]\"\n",
        "  for i in range(max_decoded_sentence_length):\n",
        "    tokenized_target_sentence = query_vectorization([decoded_sentence])\n",
        "    next_token_predictions = seq2seq_04.predict([tokenized_input_sentence, tokenized_target_sentence])\n",
        "    sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
        "\n",
        "    sampled_token = query_index_lookup[sampled_token_index]\n",
        "    decoded_sentence += \" \" + sampled_token\n",
        "    if sampled_token == \"[end]\":\n",
        "      break\n",
        "  return decoded_sentence"
      ],
      "metadata": {
        "id": "KLsS4KPVUU7c"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in test_pairs]\n",
        "query_texts = [pair[1] for pair in test_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_04(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Test Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1wHsKCuUU7c",
        "outputId": "f4194c11-3e48-4cc2-e403-3e7b9d44fdca"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-1 Score on Test Dataset: 0.153336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_questions_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(5):\n",
        "  input_sentence = random.choice(test_questions_texts)\n",
        "  print(\"-\")\n",
        "  print(input_sentence)\n",
        "  print(decode_sequence_04(input_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8ASvka6UU7c",
        "outputId": "03dec837-ebd6-47bf-c38a-df73924b717f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "What are the distinct names of wines with prices higher than any wine from John Anthony winery.\n",
            "[start] select name from customer where name = (select select ( ( ) from state where state_name = ( select max\n",
            "-\n",
            "Show the movie titles and book titles for all companies in China.\n",
            "[start] select name from customer where name = (select select ( ( ) from state where state_name = ( select max\n",
            "-\n",
            "Find the average elevation of all airports for each country.\n",
            "[start] select name from customer as t1 join author as t1 on t1.id = t2.customer_id where t1.name = \"san and t2.year\n",
            "-\n",
            "What are the names of the services that have never been used?\n",
            "[start] select name from state where state_name = ( select max ( area ) from state ); [end]\n",
            "-\n",
            "Show the budget type code and description and the corresponding document id.\n",
            "[start] select name from customer where name = (select select ( ( ) from state where state_name = ( select max\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I am sorry my GPU hours got exhausted before I could execute the below cell"
      ],
      "metadata": {
        "id": "OHq07k8tvA2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in val_pairs]\n",
        "query_texts = [pair[1] for pair in val_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_04(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Validation Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "metadata": {
        "id": "dWlfEw1DUU7c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}